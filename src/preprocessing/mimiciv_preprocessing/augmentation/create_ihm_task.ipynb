{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_iv_path = \"/data/wang/junh/datasets/physionet.org/files/mimiciv/2.2\"\n",
    "mm_dir = \"/data/wang/junh/datasets/multimodal\"\n",
    "\n",
    "output_dir = os.path.join(mm_dir, \"preprocessing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "restrict_48_hours = True\n",
    "include_notes = True\n",
    "include_cxr = True\n",
    "include_ecg = True\n",
    "standard_scale = True\n",
    "include_missing = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['subject_id', 'hadm_id', 'stay_id', 'timedelta', 'Anion Gap',\n",
      "       'Bicarbonate', 'Calcium, Total', 'Chloride', 'Creatinine',\n",
      "       'Diastolic BP', 'GCS - Eye Opening', 'GCS - Motor Response',\n",
      "       'GCS - Verbal Response', 'Glucose', 'Heart Rate', 'Hematocrit',\n",
      "       'Hemoglobin', 'MCH', 'MCHC', 'MCV', 'Magnesium', 'Mean BP',\n",
      "       'Neutrophils', 'O2 Saturation', 'Phosphate', 'Platelet Count', 'RDW',\n",
      "       'Red Blood Cells', 'Respiratory Rate', 'Sodium', 'Systolic BP',\n",
      "       'Urea Nitrogen', 'Vancomycin', 'White Blood Cells'],\n",
      "      dtype='object')\n",
      "Index(['subject_id', 'hadm_id', 'stay_id', 'timedelta', 'Anion Gap',\n",
      "       'Bicarbonate', 'Calcium, Total', 'Chloride', 'Creatinine',\n",
      "       'Diastolic BP', 'GCS - Eye Opening', 'GCS - Motor Response',\n",
      "       'GCS - Verbal Response', 'Glucose', 'Heart Rate', 'Hematocrit',\n",
      "       'Hemoglobin', 'MCH', 'MCHC', 'MCV', 'Magnesium', 'Mean BP',\n",
      "       'Neutrophils', 'O2 Saturation', 'Phosphate', 'Platelet Count', 'RDW',\n",
      "       'Red Blood Cells', 'Respiratory Rate', 'Sodium', 'Systolic BP',\n",
      "       'Urea Nitrogen', 'Vancomycin', 'White Blood Cells'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "ireg_vitals_ts_df = pd.read_pickle(os.path.join(output_dir, \"ts_labs_vitals_new.pkl\"))\n",
    "ireg_vitals_ts_df = ireg_vitals_ts_df.drop(columns=[\"hosp_time_delta\"])\n",
    "ireg_vitals_ts_df.rename(columns={'icu_time_delta': 'timedelta'}, inplace=True)\n",
    "imputed_vitals = pd.read_pickle(os.path.join(output_dir, \"imputed_ts_labs_vitals_new.pkl\"))\n",
    "\n",
    "# ireg_vitals_ts_df = pd.read_pickle(os.path.join(output_dir, \"ts_labs_vitals_icu.pkl\"))\n",
    "# imputed_vitals = pd.read_pickle(os.path.join(output_dir, \"imputed_ts_labs_vitals_icu.pkl\"))\n",
    "print(ireg_vitals_ts_df.columns)\n",
    "print(imputed_vitals.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "print(len(ireg_vitals_ts_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ireg_vitals_ts_df = ireg_vitals_ts_df[ireg_vitals_ts_df['timedelta'] >= 0]\n",
    "imputed_vitals = imputed_vitals[imputed_vitals['timedelta'] >= 0]\n",
    "\n",
    "if restrict_48_hours:\n",
    "    ireg_vitals_ts_df = ireg_vitals_ts_df[ireg_vitals_ts_df['timedelta'] <= 48]\n",
    "    imputed_vitals = imputed_vitals[imputed_vitals['timedelta'] <= 48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['note_id', 'subject_id', 'hadm_id', 'note_type', 'note_seq',\n",
      "       'charttime', 'storetime', 'text', 'stay_id', 'icu_time_delta',\n",
      "       'hosp_time_delta', 'biobert_embeddings'],\n",
      "      dtype='object')\n",
      "Index(['dicom_id', 'subject_id', 'study_id',\n",
      "       'PerformedProcedureStepDescription', 'ViewPosition',\n",
      "       'ProcedureCodeSequence_CodeMeaning', 'ViewCodeSequence_CodeMeaning',\n",
      "       'PatientOrientationCodeSequence_CodeMeaning', 'densefeatures',\n",
      "       'predictions', 'cxrtime', 'hadm_id', 'stay_id', 'icu_time_delta',\n",
      "       'hosp_time_delta'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "if include_notes:\n",
    "    notes_df = pd.read_pickle(os.path.join(output_dir, \"icu_notes_text_embeddings.pkl\"))\n",
    "    print(notes_df.columns)\n",
    "    # notes_df = pd.read_pickle(os.path.join(output_dir, \"notes_text.pkl\"))\n",
    "    notes_df = notes_df[notes_df['stay_id'].notnull()]\n",
    "\n",
    "    notes_df = notes_df[notes_df['icu_time_delta'] >= 0]\n",
    "    if restrict_48_hours:\n",
    "        notes_df = notes_df[notes_df['icu_time_delta'] <= 48]\n",
    "\n",
    "if include_cxr:\n",
    "    cxr_df = pd.read_pickle(os.path.join(output_dir, \"cxr_embeddings_stay.pkl\"))\n",
    "    print(cxr_df.columns)\n",
    "    cxr_df = cxr_df[cxr_df['icu_time_delta'] >= 0]\n",
    "    if restrict_48_hours:\n",
    "        cxr_df = cxr_df[cxr_df['icu_time_delta'] <= 48]\n",
    "\n",
    "if include_ecg:\n",
    "    ecg_df = pd.read_pickle(os.path.join(output_dir, \"ecg_embeddings_icu.pkl\"))\n",
    "    ecg_df = ecg_df[ecg_df['icu_time_delta'] >= 0]\n",
    "    if restrict_48_hours:\n",
    "        ecg_df = ecg_df[ecg_df['icu_time_delta'] <= 48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dicom_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>study_id</th>\n",
       "      <th>PerformedProcedureStepDescription</th>\n",
       "      <th>ViewPosition</th>\n",
       "      <th>ProcedureCodeSequence_CodeMeaning</th>\n",
       "      <th>ViewCodeSequence_CodeMeaning</th>\n",
       "      <th>PatientOrientationCodeSequence_CodeMeaning</th>\n",
       "      <th>densefeatures</th>\n",
       "      <th>predictions</th>\n",
       "      <th>cxrtime</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>stay_id</th>\n",
       "      <th>icu_time_delta</th>\n",
       "      <th>hosp_time_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>7b25b3ed-e780a527-319cb7b3-02d5d071-f1cddee9</td>\n",
       "      <td>10001884</td>\n",
       "      <td>50712381</td>\n",
       "      <td>CHEST (PORTABLE AP)</td>\n",
       "      <td>AP</td>\n",
       "      <td>CHEST (PORTABLE AP)</td>\n",
       "      <td>antero-posterior</td>\n",
       "      <td>Erect</td>\n",
       "      <td>[0.004360755, 0.10861953, 0.0656413, 0.0077615...</td>\n",
       "      <td>[0.83476615, 0.6821718, 0.5, 0.5015653, 0.7613...</td>\n",
       "      <td>2131-01-12 04:56:56</td>\n",
       "      <td>26184834</td>\n",
       "      <td>37510196</td>\n",
       "      <td>24.614167</td>\n",
       "      <td>104.298889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>38f6981f-10343eb8-7c974e21-458d5218-f29f1617</td>\n",
       "      <td>10002428</td>\n",
       "      <td>50862960</td>\n",
       "      <td>CHEST (PORTABLE AP)</td>\n",
       "      <td>AP</td>\n",
       "      <td>CHEST (PORTABLE AP)</td>\n",
       "      <td>antero-posterior</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.0026520048, 0.021410752, 0.23664735, 0.0120...</td>\n",
       "      <td>[0.77319604, 0.6379471, 0.5, 0.2651843, 0.8441...</td>\n",
       "      <td>2156-04-21 02:24:51</td>\n",
       "      <td>28662225</td>\n",
       "      <td>38875437</td>\n",
       "      <td>32.225556</td>\n",
       "      <td>204.1475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>4e39ddbc-47422ff9-3de977e6-924e3c52-4cac3943</td>\n",
       "      <td>10002428</td>\n",
       "      <td>51574899</td>\n",
       "      <td>CHEST (PORTABLE AP)</td>\n",
       "      <td>AP</td>\n",
       "      <td>CHEST (PORTABLE AP)</td>\n",
       "      <td>antero-posterior</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.0007566094, 0.029454479, 0.20461331, 0.0143...</td>\n",
       "      <td>[0.9089313, 0.8434784, 0.5, 0.5104989, 0.76865...</td>\n",
       "      <td>2156-04-21 11:13:19</td>\n",
       "      <td>28662225</td>\n",
       "      <td>38875437</td>\n",
       "      <td>41.033333</td>\n",
       "      <td>212.955278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>54c2ed5c-f4fbc20d-3bf4c783-283c3878-e9eb320d</td>\n",
       "      <td>10002428</td>\n",
       "      <td>52460896</td>\n",
       "      <td>CHEST (PORTABLE AP)</td>\n",
       "      <td>AP</td>\n",
       "      <td>CHEST (PORTABLE AP)</td>\n",
       "      <td>antero-posterior</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.0022582188, 0.04897062, 0.21259578, 0.02378...</td>\n",
       "      <td>[0.8172648, 0.7462012, 0.5, 0.37802082, 0.7915...</td>\n",
       "      <td>2156-05-12 04:07:00</td>\n",
       "      <td>23473524</td>\n",
       "      <td>35479615</td>\n",
       "      <td>13.290556</td>\n",
       "      <td>13.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>217e6a56-b4a78227-a2acc34d-3b571d4a-27b9746a</td>\n",
       "      <td>10002428</td>\n",
       "      <td>57064083</td>\n",
       "      <td>CHEST (PORTABLE AP)</td>\n",
       "      <td>AP</td>\n",
       "      <td>CHEST (PORTABLE AP)</td>\n",
       "      <td>antero-posterior</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.0008703213, 0.06460024, 0.2580139, 0.002456...</td>\n",
       "      <td>[0.8643331, 0.8319758, 0.5, 0.33241627, 0.8501...</td>\n",
       "      <td>2156-05-11 18:46:22</td>\n",
       "      <td>23473524</td>\n",
       "      <td>35479615</td>\n",
       "      <td>3.946667</td>\n",
       "      <td>3.956111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         dicom_id  subject_id  study_id  \\\n",
       "72   7b25b3ed-e780a527-319cb7b3-02d5d071-f1cddee9    10001884  50712381   \n",
       "150  38f6981f-10343eb8-7c974e21-458d5218-f29f1617    10002428  50862960   \n",
       "151  4e39ddbc-47422ff9-3de977e6-924e3c52-4cac3943    10002428  51574899   \n",
       "152  54c2ed5c-f4fbc20d-3bf4c783-283c3878-e9eb320d    10002428  52460896   \n",
       "160  217e6a56-b4a78227-a2acc34d-3b571d4a-27b9746a    10002428  57064083   \n",
       "\n",
       "    PerformedProcedureStepDescription ViewPosition  \\\n",
       "72                CHEST (PORTABLE AP)           AP   \n",
       "150               CHEST (PORTABLE AP)           AP   \n",
       "151               CHEST (PORTABLE AP)           AP   \n",
       "152               CHEST (PORTABLE AP)           AP   \n",
       "160               CHEST (PORTABLE AP)           AP   \n",
       "\n",
       "    ProcedureCodeSequence_CodeMeaning ViewCodeSequence_CodeMeaning  \\\n",
       "72                CHEST (PORTABLE AP)             antero-posterior   \n",
       "150               CHEST (PORTABLE AP)             antero-posterior   \n",
       "151               CHEST (PORTABLE AP)             antero-posterior   \n",
       "152               CHEST (PORTABLE AP)             antero-posterior   \n",
       "160               CHEST (PORTABLE AP)             antero-posterior   \n",
       "\n",
       "    PatientOrientationCodeSequence_CodeMeaning  \\\n",
       "72                                       Erect   \n",
       "150                                        NaN   \n",
       "151                                        NaN   \n",
       "152                                        NaN   \n",
       "160                                        NaN   \n",
       "\n",
       "                                         densefeatures  \\\n",
       "72   [0.004360755, 0.10861953, 0.0656413, 0.0077615...   \n",
       "150  [0.0026520048, 0.021410752, 0.23664735, 0.0120...   \n",
       "151  [0.0007566094, 0.029454479, 0.20461331, 0.0143...   \n",
       "152  [0.0022582188, 0.04897062, 0.21259578, 0.02378...   \n",
       "160  [0.0008703213, 0.06460024, 0.2580139, 0.002456...   \n",
       "\n",
       "                                           predictions             cxrtime  \\\n",
       "72   [0.83476615, 0.6821718, 0.5, 0.5015653, 0.7613... 2131-01-12 04:56:56   \n",
       "150  [0.77319604, 0.6379471, 0.5, 0.2651843, 0.8441... 2156-04-21 02:24:51   \n",
       "151  [0.9089313, 0.8434784, 0.5, 0.5104989, 0.76865... 2156-04-21 11:13:19   \n",
       "152  [0.8172648, 0.7462012, 0.5, 0.37802082, 0.7915... 2156-05-12 04:07:00   \n",
       "160  [0.8643331, 0.8319758, 0.5, 0.33241627, 0.8501... 2156-05-11 18:46:22   \n",
       "\n",
       "      hadm_id   stay_id icu_time_delta hosp_time_delta  \n",
       "72   26184834  37510196      24.614167      104.298889  \n",
       "150  28662225  38875437      32.225556        204.1475  \n",
       "151  28662225  38875437      41.033333      212.955278  \n",
       "152  23473524  35479615      13.290556            13.3  \n",
       "160  23473524  35479615       3.946667        3.956111  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cxr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "icustays_df = pd.read_csv(os.path.join(mimic_iv_path, \"icu\", \"icustays.csv.gz\"), low_memory=False)\n",
    "icustays_df['intime'] = pd.to_datetime(icustays_df['intime'])\n",
    "icustays_df['outtime'] = pd.to_datetime(icustays_df['outtime'])\n",
    "\n",
    "if restrict_48_hours:\n",
    "    icustays_df = icustays_df[icustays_df['los'] >= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_stay_ids = icustays_df['stay_id'].unique()\n",
    "\n",
    "ireg_vitals_ts_df = ireg_vitals_ts_df[ireg_vitals_ts_df['stay_id'].isin(valid_stay_ids)]\n",
    "imputed_vitals = imputed_vitals[imputed_vitals['stay_id'].isin(valid_stay_ids)]\n",
    "\n",
    "if include_notes:\n",
    "    notes_df = notes_df[notes_df['stay_id'].isin(valid_stay_ids)]\n",
    "\n",
    "if include_cxr:\n",
    "    cxr_df = cxr_df[cxr_df['stay_id'].isin(valid_stay_ids)]\n",
    "\n",
    "if include_ecg:\n",
    "    ecg_df = ecg_df[ecg_df['stay_id'].isin(valid_stay_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>stay_id</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>Anion Gap</th>\n",
       "      <th>Bicarbonate</th>\n",
       "      <th>Calcium, Total</th>\n",
       "      <th>Chloride</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>Diastolic BP</th>\n",
       "      <th>...</th>\n",
       "      <th>Phosphate</th>\n",
       "      <th>Platelet Count</th>\n",
       "      <th>RDW</th>\n",
       "      <th>Red Blood Cells</th>\n",
       "      <th>Respiratory Rate</th>\n",
       "      <th>Sodium</th>\n",
       "      <th>Systolic BP</th>\n",
       "      <th>Urea Nitrogen</th>\n",
       "      <th>Vancomycin</th>\n",
       "      <th>White Blood Cells</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2523449</th>\n",
       "      <td>10001884</td>\n",
       "      <td>26184834.0</td>\n",
       "      <td>37510196</td>\n",
       "      <td>0.031944</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2523450</th>\n",
       "      <td>10001884</td>\n",
       "      <td>26184834.0</td>\n",
       "      <td>37510196</td>\n",
       "      <td>0.081944</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2523451</th>\n",
       "      <td>10001884</td>\n",
       "      <td>26184834.0</td>\n",
       "      <td>37510196</td>\n",
       "      <td>0.665278</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2523452</th>\n",
       "      <td>10001884</td>\n",
       "      <td>26184834.0</td>\n",
       "      <td>37510196</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2523453</th>\n",
       "      <td>10001884</td>\n",
       "      <td>26184834.0</td>\n",
       "      <td>37510196</td>\n",
       "      <td>1.665278</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         subject_id     hadm_id   stay_id timedelta  Anion Gap  Bicarbonate  \\\n",
       "2523449    10001884  26184834.0  37510196  0.031944        NaN          NaN   \n",
       "2523450    10001884  26184834.0  37510196  0.081944        NaN          NaN   \n",
       "2523451    10001884  26184834.0  37510196  0.665278        NaN          NaN   \n",
       "2523452    10001884  26184834.0  37510196  0.681944        NaN          NaN   \n",
       "2523453    10001884  26184834.0  37510196  1.665278        NaN          NaN   \n",
       "\n",
       "         Calcium, Total  Chloride  Creatinine  Diastolic BP  ...  Phosphate  \\\n",
       "2523449             NaN       NaN         NaN           NaN  ...        NaN   \n",
       "2523450             NaN       NaN         NaN          12.0  ...        NaN   \n",
       "2523451             NaN       NaN         NaN           NaN  ...        NaN   \n",
       "2523452             NaN       NaN         NaN          49.0  ...        NaN   \n",
       "2523453             NaN       NaN         NaN           NaN  ...        NaN   \n",
       "\n",
       "         Platelet Count  RDW  Red Blood Cells  Respiratory Rate  Sodium  \\\n",
       "2523449             NaN  NaN              NaN               NaN     NaN   \n",
       "2523450             NaN  NaN              NaN               NaN     NaN   \n",
       "2523451             NaN  NaN              NaN              10.0     NaN   \n",
       "2523452             NaN  NaN              NaN               NaN     NaN   \n",
       "2523453             NaN  NaN              NaN              20.0     NaN   \n",
       "\n",
       "         Systolic BP  Urea Nitrogen  Vancomycin  White Blood Cells  \n",
       "2523449          NaN            NaN         NaN                NaN  \n",
       "2523450        180.0            NaN         NaN                NaN  \n",
       "2523451          NaN            NaN         NaN                NaN  \n",
       "2523452        167.0            NaN         NaN                NaN  \n",
       "2523453          NaN            NaN         NaN                NaN  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ireg_vitals_ts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stays in cxr:  8781\n",
      "Number of stays in notes:  32040\n"
     ]
    }
   ],
   "source": [
    "#print(\"Number of stays in ecg: \", ecg_df['stay_id'].nunique())\n",
    "print(\"Number of stays in cxr: \", cxr_df['stay_id'].nunique())\n",
    "print(\"Number of stays in notes: \", notes_df['stay_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3014705, 34)\n"
     ]
    }
   ],
   "source": [
    "print(ireg_vitals_ts_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions_df = pd.read_csv(os.path.join(mimic_iv_path, \"hosp\", \"admissions.csv.gz\"))\n",
    "admissions_df = admissions_df.rename(columns={\"hospital_expire_flag\": \"died\"})\n",
    "admissions_df = admissions_df[[\"subject_id\", \"hadm_id\", \"died\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stays with vitals: 35131\n",
      "Number of stays with notes: 32040\n",
      "Number of stays with cxr: 8770\n",
      "Number of stays with ecg: 5178\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if not include_missing:\n",
    "    unique_stays = ireg_vitals_ts_df['stay_id'].unique()\n",
    "    print(f\"Number of stays with vitals: {len(unique_stays)}\")\n",
    "\n",
    "    if include_notes:\n",
    "        unique_stays = np.intersect1d(unique_stays, notes_df['stay_id'].unique())\n",
    "        print(f\"Number of stays with notes: {len(unique_stays)}\")\n",
    "\n",
    "    if include_cxr:\n",
    "        unique_stays = np.intersect1d(unique_stays, cxr_df['stay_id'].unique())\n",
    "        print(f\"Number of stays with cxr: {len(unique_stays)}\")\n",
    "\n",
    "    if include_ecg:\n",
    "        unique_stays = np.intersect1d(unique_stays, ecg_df['stay_id'].unique())\n",
    "        print(f\"Number of stays with ecg: {len(unique_stays)}\")\n",
    "else:\n",
    "    unique_stays = ireg_vitals_ts_df['stay_id'].unique()\n",
    "    print(f\"Number of stays with vitals: {len(unique_stays)}\")\n",
    "\n",
    "    if include_notes:\n",
    "        # Get stays with either TS or notes\n",
    "        unique_stays = np.union1d(unique_stays, notes_df['stay_id'].unique())\n",
    "        print(f\"Number of stays with either TS or notes: {len(unique_stays)}\")\n",
    "    \n",
    "    if include_cxr:\n",
    "        unique_stays = np.union1d(unique_stays, cxr_df['stay_id'].unique())\n",
    "        print(f\"Number of stays with either TS, notes, cxr: {len(unique_stays)}\")\n",
    "    \n",
    "    if include_ecg:\n",
    "        unique_stays = np.union1d(unique_stays, ecg_df['stay_id'].unique())\n",
    "        print(f\"Number of stays with either TS, notes, cxr, ecg: {len(unique_stays)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "stays_with_labels = []\n",
    "stay_to_hadm_mapping = dict(zip(ireg_vitals_ts_df['stay_id'], ireg_vitals_ts_df['hadm_id']))\n",
    "\n",
    "for stay in unique_stays:\n",
    "    curr_stay_dict = {}\n",
    "    curr_stay_dict['stay_id'] = stay\n",
    "\n",
    "    # Retrieve hadm_id using the mapping\n",
    "    if stay in stay_to_hadm_mapping:\n",
    "        curr_stay_dict['hadm_id'] = stay_to_hadm_mapping[stay]\n",
    "        # Retrieve the label (e.g., 'died') from admissions_df\n",
    "        curr_stay_dict['label'] = admissions_df[\n",
    "            admissions_df['hadm_id'] == curr_stay_dict['hadm_id']\n",
    "        ]['died'].iloc[0]\n",
    "\n",
    "    stays_with_labels.append(curr_stay_dict)\n",
    "\n",
    "stays_df = pd.DataFrame(stays_with_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create train, val, test splits\n",
    "# np.random.seed(0)\n",
    "# np.random.shuffle(unique_stays)\n",
    "# train_stays = unique_stays[:int(0.7*len(unique_stays))]\n",
    "# val_stays = unique_stays[int(0.7*len(unique_stays)):int(0.85*len(unique_stays))]\n",
    "# test_stays = unique_stays[int(0.85*len(unique_stays)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = stays_df.groupby('label')\n",
    "train_stays, val_stays, test_stays = [], [], []\n",
    "\n",
    "np.random.seed(0)  # Ensure reproducibility\n",
    "\n",
    "for label, group in groups:\n",
    "    shuffled_group = group.sample(frac=1, random_state=0)  # Shuffle\n",
    "    n = len(shuffled_group)\n",
    "    \n",
    "    # Calculate split indices\n",
    "    train_end = int(0.7 * n)\n",
    "    val_end = int(0.85 * n)\n",
    "    \n",
    "    # Append stratified splits\n",
    "    train_stays.extend(shuffled_group.iloc[:train_end].to_dict('records'))\n",
    "    val_stays.extend(shuffled_group.iloc[train_end:val_end].to_dict('records'))\n",
    "    test_stays.extend(shuffled_group.iloc[val_end:].to_dict('records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert train_stays, val_stays, and test_stays dictionaries back to unique_stays format\n",
    "train_stays = [stay['stay_id'] for stay in train_stays]\n",
    "val_stays = [stay['stay_id'] for stay in val_stays]\n",
    "test_stays = [stay['stay_id'] for stay in test_stays]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ireg_ts_df = ireg_vitals_ts_df[ireg_vitals_ts_df['stay_id'].isin(train_stays)].copy()\n",
    "train_imputed_df = imputed_vitals[imputed_vitals['stay_id'].isin(train_stays)].copy()\n",
    "\n",
    "cols = train_ireg_ts_df.columns.tolist()\n",
    "cols = [col for col in cols if col not in ['subject_id', 'hadm_id', 'stay_id', 'timedelta']]\n",
    "\n",
    "if standard_scale:\n",
    "    for col in cols:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(train_ireg_ts_df[[col]])\n",
    "        ireg_vitals_ts_df[col] = scaler.transform(ireg_vitals_ts_df[[col]])\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(train_imputed_df[[col]])\n",
    "        imputed_vitals[col] = scaler.transform(imputed_vitals[[col]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['subject_id', 'hadm_id', 'stay_id', 'timedelta', 'Anion Gap',\n",
      "       'Bicarbonate', 'Calcium, Total', 'Chloride', 'Creatinine',\n",
      "       'Diastolic BP', 'GCS - Eye Opening', 'GCS - Motor Response',\n",
      "       'GCS - Verbal Response', 'Glucose', 'Heart Rate', 'Hematocrit',\n",
      "       'Hemoglobin', 'MCH', 'MCHC', 'MCV', 'Magnesium', 'Mean BP',\n",
      "       'Neutrophils', 'O2 Saturation', 'Phosphate', 'Platelet Count', 'RDW',\n",
      "       'Red Blood Cells', 'Respiratory Rate', 'Sodium', 'Systolic BP',\n",
      "       'Urea Nitrogen', 'Vancomycin', 'White Blood Cells'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_ireg_ts_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stay_list(stays):\n",
    "    stays_list = []\n",
    "\n",
    "    for curr_stay in tqdm(stays):\n",
    "        curr_stay_ireg = ireg_vitals_ts_df[ireg_vitals_ts_df['stay_id'] == curr_stay].copy()\n",
    "        curr_stay_imputed = imputed_vitals[imputed_vitals['stay_id'] == curr_stay].copy()\n",
    "\n",
    "        if len(curr_stay_ireg) == 0:\n",
    "            continue\n",
    "\n",
    "        curr_stay_dict = {}\n",
    "        curr_stay_dict['name'] = curr_stay_ireg['subject_id'].iloc[0]\n",
    "        curr_stay_dict['hadm_id'] = curr_stay_ireg['hadm_id'].iloc[0]\n",
    "        curr_stay_dict['stay_id'] = curr_stay\n",
    "        curr_stay_dict['ts_tt'] = curr_stay_ireg['timedelta'].values\n",
    "\n",
    "        # Save the feature names before dropping unnecessary columns\n",
    "        feature_names = curr_stay_ireg.drop(columns=['subject_id', 'hadm_id', 'stay_id', 'timedelta']).columns.tolist()\n",
    "        curr_stay_ireg.drop(columns=['subject_id', 'hadm_id', 'stay_id', 'timedelta'], inplace=True)\n",
    "        ireg_ts_mask = curr_stay_ireg.notnull()\n",
    "        curr_stay_ireg.fillna(0, inplace=True)\n",
    "        curr_stay_dict['irg_ts'] = curr_stay_ireg.values\n",
    "        curr_stay_dict['irg_ts_mask'] = ireg_ts_mask.values.astype(int)\n",
    "\n",
    "        curr_stay_imputed.drop(columns=['subject_id', 'hadm_id', 'stay_id', 'timedelta'], inplace=True)\n",
    "        curr_stay_dict['reg_ts'] = curr_stay_imputed.values\n",
    "\n",
    "        if include_notes:\n",
    "            curr_stay_notes = notes_df[notes_df['stay_id'] == curr_stay].copy()\n",
    "            if len(curr_stay_notes) == 0:\n",
    "                curr_stay_dict['text_data'] = []\n",
    "                curr_stay_dict['text_time_to_end'] = []\n",
    "                curr_stay_dict['text_embeddings'] = []\n",
    "                curr_stay_dict['text_missing'] = 1\n",
    "            else:\n",
    "                curr_stay_dict['text_data'] = curr_stay_notes['text'].tolist()\n",
    "                curr_stay_dict['text_time_to_end'] = curr_stay_notes['icu_time_delta'].values\n",
    "                curr_stay_dict['text_embeddings'] = [emb[0][0] for emb in curr_stay_notes['biobert_embeddings']]\n",
    "                curr_stay_dict['text_missing'] = 0\n",
    "\n",
    "        if include_cxr:\n",
    "            curr_stay_cxr = cxr_df[cxr_df['stay_id'] == curr_stay].copy()\n",
    "            if curr_stay_cxr.empty:\n",
    "                curr_stay_dict['cxr_metadata'] = []\n",
    "                curr_stay_dict['image_paths'] = []\n",
    "                curr_stay_dict['cxr_missing'] = 1\n",
    "            else:\n",
    "                curr_stay_dict['cxr_feats'] = curr_stay_cxr['densefeatures'].tolist()\n",
    "                metadata = curr_stay_cxr[['dicom_id', 'PerformedProcedureStepDescription', 'ViewPosition', 'ProcedureCodeSequence_CodeMeaning', 'ViewCodeSequence_CodeMeaning', 'PatientOrientationCodeSequence_CodeMeaning']].to_dict('records')\n",
    "                curr_stay_dict['cxr_metadata'] = metadata\n",
    "                image_paths = curr_stay_cxr.apply(lambda row: os.path.join('/data/wang/junh/datasets/physionet.org/files/mimic-cxr-jpg/2.0.0/mimic-cxr-jpg-2.1.0.physionet.org/files', f\"p{str(row['subject_id'])[:2]}\", f\"p{row['subject_id']}\", f\"s{row['study_id']}\", f\"{row['dicom_id']}.jpg\"), axis=1).tolist()\n",
    "                curr_stay_dict['image_paths'] = image_paths\n",
    "                curr_stay_dict['cxr_time'] = curr_stay_cxr['icu_time_delta'].values\n",
    "                curr_stay_dict['cxr_missing'] = 0\n",
    "\n",
    "        if include_ecg and ecg_df is not None:\n",
    "            curr_stay_ecg = ecg_df[ecg_df['stay_id'] == curr_stay].copy()\n",
    "            if len(curr_stay_ecg) == 0:\n",
    "                curr_stay_dict['ecg_feats'] = []\n",
    "                curr_stay_dict['ecg_time'] = []\n",
    "                curr_stay_dict['ecg_missing'] = 1\n",
    "            else:\n",
    "                curr_stay_dict['ecg_feats'] = curr_stay_ecg['embeddings'].tolist()\n",
    "                curr_stay_dict['ecg_time'] = curr_stay_ecg['icu_time_delta'].values\n",
    "                curr_stay_dict['ecg_missing'] = 0\n",
    "\n",
    "        if admissions_df is not None:\n",
    "            curr_stay_dict['label'] = admissions_df[admissions_df['hadm_id'] == curr_stay_dict['hadm_id']]['died'].iloc[0]\n",
    "\n",
    "        stays_list.append(curr_stay_dict)\n",
    "\n",
    "    return stays_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_stay_list(stays):\n",
    "#     stays_list = []\n",
    "\n",
    "#     for curr_stay in tqdm(stays):\n",
    "        \n",
    "#         curr_stay_ireg = ireg_vitals_ts_df[ireg_vitals_ts_df['stay_id'] == curr_stay].copy()\n",
    "#         print(curr_stay_ireg)\n",
    "#         #print(f\"Initial irregular time series shape (before dropping columns): {curr_stay_ireg.shape}\")\n",
    "#         curr_stay_imputed = imputed_vitals[imputed_vitals['stay_id'] == curr_stay].copy()\n",
    "\n",
    "#         if len(curr_stay_ireg) == 0:\n",
    "#             continue\n",
    "\n",
    "#         curr_stay_dict = {}\n",
    "#         curr_stay_dict['name'] = curr_stay_ireg['subject_id'].iloc[0]\n",
    "#         curr_stay_dict['hadm_id'] = curr_stay_ireg['hadm_id'].iloc[0]\n",
    "#         curr_stay_dict['stay_id'] = curr_stay\n",
    "#         curr_stay_dict['ts_tt'] = curr_stay_ireg['timedelta'].values\n",
    "\n",
    "#         curr_stay_ireg.drop(columns=['subject_id', 'hadm_id', 'stay_id', 'timedelta'], inplace=True)\n",
    "#         ireg_ts_mask = curr_stay_ireg.notnull()\n",
    "#         curr_stay_ireg.fillna(0, inplace=True)\n",
    "#         curr_stay_dict['irg_ts'] = curr_stay_ireg.values\n",
    "#         curr_stay_dict['irg_ts_mask'] = ireg_ts_mask.values.astype(int)\n",
    "\n",
    "#         curr_stay_imputed.drop(columns=['subject_id', 'hadm_id', 'stay_id', 'timedelta'], inplace=True)\n",
    "#         curr_stay_dict['reg_ts'] = curr_stay_imputed.values\n",
    "\n",
    "#         if include_notes:\n",
    "#             curr_stay_notes = notes_df[notes_df['stay_id'] == curr_stay].copy()\n",
    "\n",
    "#             if len(curr_stay_notes) == 0:\n",
    "#                 curr_stay_dict['text_data'] = []\n",
    "#                 curr_stay_dict['text_time_to_end'] = []\n",
    "#                 curr_stay_dict['text_embeddings'] = []\n",
    "#                 curr_stay_dict['text_missing'] = 1\n",
    "#             else:\n",
    "#                 curr_stay_dict['text_data'] = curr_stay_notes['text'].tolist()\n",
    "#                 curr_stay_dict['text_time_to_end'] = curr_stay_notes['icu_time_delta'].values\n",
    "#                 # a list of the first [CLS] embedding vectors \n",
    "#                 # of the first chunk for each note in curr_stay_notes\n",
    "#                 curr_stay_dict['text_embeddings'] = [emb[0][0] for emb in curr_stay_notes['biobert_embeddings']]\n",
    "#                 curr_stay_dict['text_missing'] = 0\n",
    "\n",
    "#         if include_cxr:\n",
    "#             curr_stay_cxr = cxr_df[cxr_df['stay_id'] == curr_stay].copy()\n",
    "            \n",
    "#             if len(curr_stay_cxr) == 0:\n",
    "#                 curr_stay_dict['cxr_feats'] = []\n",
    "#                 curr_stay_dict['cxr_time'] = []\n",
    "#                 curr_stay_dict['cxr_missing'] = 1\n",
    "#             else:\n",
    "#                 curr_stay_dict['cxr_feats'] = curr_stay_cxr['densefeatures'].tolist()\n",
    "#                 curr_stay_dict['cxr_time'] = curr_stay_cxr['icu_time_delta'].values\n",
    "#                 curr_stay_dict['cxr_missing'] = 0\n",
    "#                 #print(f\"Number of CXR features: {len(curr_stay_dict['cxr_feats'])}\")\n",
    "\n",
    "#         if include_ecg:\n",
    "#             curr_stay_ecg = ecg_df[ecg_df['stay_id'] == curr_stay].copy()\n",
    "#             if len(curr_stay_ecg) == 0:\n",
    "#                 curr_stay_dict['ecg_feats'] = []\n",
    "#                 curr_stay_dict['ecg_time'] = []\n",
    "#                 curr_stay_dict['ecg_missing'] = 1\n",
    "#             else:\n",
    "#                 curr_stay_dict['ecg_feats'] = curr_stay_ecg['embeddings'].tolist()\n",
    "#                 curr_stay_dict['ecg_time'] = curr_stay_ecg['icu_time_delta'].values\n",
    "#                 curr_stay_dict['ecg_missing'] = 0\n",
    "\n",
    "#         curr_stay_dict['label'] = admissions_df[admissions_df['hadm_id'] == curr_stay_dict['hadm_id']]['died'].iloc[0]\n",
    "\n",
    "#         stays_list.append(curr_stay_dict)\n",
    "\n",
    "#     return stays_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3624/3624 [09:02<00:00,  6.68it/s]\n",
      "100%|██████████| 776/776 [01:55<00:00,  6.72it/s]\n",
      "100%|██████████| 778/778 [01:54<00:00,  6.79it/s]\n"
     ]
    }
   ],
   "source": [
    "train_stays_list = get_stay_list(train_stays)\n",
    "val_stays_list = get_stay_list(val_stays)\n",
    "test_stays_list = get_stay_list(test_stays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  7.16it/s]\n"
     ]
    }
   ],
   "source": [
    "# Example to check the first patient stay\n",
    "first_stay = train_stays[18]\n",
    "first_stay_data = get_stay_list([first_stay])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving train stays to /data/wang/junh/datasets/multimodal/balanced/train_ihm-48-cxr-notes-ecg_stays.pkl\n",
      "Saving val stays to /data/wang/junh/datasets/multimodal/balanced/val_ihm-48-cxr-notes-ecg_stays.pkl\n",
      "Saving test stays to /data/wang/junh/datasets/multimodal/balanced/test_ihm-48-cxr-notes-ecg_stays.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save the data\n",
    "import pickle\n",
    "\n",
    "output_dir = os.path.join(mm_dir, \"balanced\")\n",
    "\n",
    "base_name = \"ihm\"\n",
    "if restrict_48_hours:\n",
    "    base_name += \"-48\"\n",
    "else:\n",
    "    base_name += \"-all\"\n",
    "\n",
    "if include_cxr:\n",
    "    if include_notes:\n",
    "        base_name += \"-cxr-notes\"\n",
    "    else:\n",
    "        base_name += \"-cxr\"\n",
    "\n",
    "if include_ecg:\n",
    "    base_name += \"-ecg\"\n",
    "\n",
    "if include_missing:\n",
    "    base_name += \"-missingInd\"\n",
    "\n",
    "f_path = os.path.join(output_dir, f\"train_{base_name}_stays.pkl\")\n",
    "with open(f_path, 'wb') as f:\n",
    "    print(f\"Saving train stays to {f_path}\")\n",
    "    pickle.dump(train_stays_list, f)\n",
    "\n",
    "f_path = os.path.join(output_dir, f\"val_{base_name}_stays.pkl\")\n",
    "with open(f_path, 'wb') as f:\n",
    "    print(f\"Saving val stays to {f_path}\")\n",
    "    pickle.dump(val_stays_list, f)\n",
    "\n",
    "f_path = os.path.join(output_dir, f\"test_{base_name}_stays.pkl\")\n",
    "with open(f_path, 'wb') as f:\n",
    "    print(f\"Saving test stays to {f_path}\")\n",
    "    pickle.dump(test_stays_list, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6139\n"
     ]
    }
   ],
   "source": [
    "# Save the data\n",
    "import pickle\n",
    "file_path = '/data/wang/junh/datasets/multimodal/augmentation/train_ihm-48-cxr-notes_stays.pkl'\n",
    "with open(file_path, 'rb') as f:\n",
    "    train_stays_list = pickle.load(f)\n",
    "print(len(train_stays_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['name', 'hadm_id', 'stay_id', 'ts_tt', 'ts_feature_names', 'irg_ts', 'irg_ts_mask', 'reg_ts', 'text_data', 'text_time_to_end', 'text_missing', 'cxr_metadata', 'image_paths', 'cxr_missing', 'label'])\n"
     ]
    }
   ],
   "source": [
    "print(train_stays_list[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EXAMINATION:  CHEST (PORTABLE AP)\\n\\nINDICATION:  PULMONARY EDEMA\\n\\nIMPRESSION: \\n\\nIn comparison with the study of ___, there again is substantial enlargement\\nof the cardiac silhouette without pulmonary vascular congestion.  This\\ndiscordance suggests underlying cardiomyopathy or pericardial effusion.\\nThere has been placement of a right IJ Swan-Ganz catheter that extends to the\\nright pulmonary artery at the outer limits of the mediastinum.\\nNo evidence of acute focal pneumonia.\\n', 'EXAMINATION:  CHEST (PORTABLE AP)\\n\\nINDICATION:  ___ year old man with CHF s/p swan placement now not drawing back \\n// evaluate position of swan      evaluate position of swan\\n\\nCOMPARISON:  Prior chest radiographs since ___ most recently ___.\\n\\nIMPRESSION: \\n\\nSwan-Ganz catheter ends in the right descending pulmonary artery at least 2 cm\\nbeyond standard placement.  Severe cardiomegaly is chronic.  Pulmonary\\nvascular congestion has worsened although there is no pulmonary edema or\\nappreciable pleural effusion.  No pneumothorax.  Transvenous right atrial\\nright ventricular pacer defibrillator leads are continuous from the left\\naxillary generator.\\n']\n"
     ]
    }
   ],
   "source": [
    "print(train_stays_list[0].get('text_data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'dicom_id': '402f6f42-d0f23298-0bc9e9e5-bf1062eb-852e2c56', 'PerformedProcedureStepDescription': 'CHEST (PORTABLE AP)', 'ViewPosition': 'AP', 'ProcedureCodeSequence_CodeMeaning': 'CHEST (PORTABLE AP)', 'ViewCodeSequence_CodeMeaning': 'antero-posterior', 'PatientOrientationCodeSequence_CodeMeaning': 'Erect'}, {'dicom_id': 'a8151392-fe6cfae5-7128b4e0-c8ac92e3-f5c1131d', 'PerformedProcedureStepDescription': 'CHEST (PORTABLE AP)', 'ViewPosition': 'AP', 'ProcedureCodeSequence_CodeMeaning': 'CHEST (PORTABLE AP)', 'ViewCodeSequence_CodeMeaning': 'antero-posterior', 'PatientOrientationCodeSequence_CodeMeaning': 'Erect'}]\n"
     ]
    }
   ],
   "source": [
    "print(train_stays_list[0].get('cxr_metadata'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fuse_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
