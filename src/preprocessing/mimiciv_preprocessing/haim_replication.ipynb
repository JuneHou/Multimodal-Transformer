{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "from npj_utils import *\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_iv_path = \"/data/wang/junh/datasets/physionet.org/files/mimiciv/2.2\"\n",
    "mm_dir = \"/data/wang/junh/datasets/multimodal\"\n",
    "\n",
    "output_dir = os.path.join(mm_dir, \"preprocessing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "base_name = \"pheno\" # ihm, los, pheno\n",
    "\n",
    "if \"pheno\" in base_name:\n",
    "    base_name += \"-all\"\n",
    "else:\n",
    "    base_name += \"-48\"\n",
    "\n",
    "# base_name += \"-cxr-notes-ecg-missingInd\"\n",
    "base_name += \"-cxr-notes-missingInd\"\n",
    "\n",
    "f_path = os.path.join(output_dir, f\"train_{base_name}_stays.pkl\")\n",
    "\n",
    "with open(f_path, \"rb\") as f:\n",
    "    train_stays = pickle.load(f)\n",
    "\n",
    "f_path = os.path.join(output_dir, f\"val_{base_name}_stays.pkl\")\n",
    "\n",
    "with open(f_path, \"rb\") as f:\n",
    "    val_stays = pickle.load(f)\n",
    "\n",
    "f_path = os.path.join(output_dir, f\"test_{base_name}_stays.pkl\")\n",
    "\n",
    "with open(f_path, \"rb\") as f:\n",
    "    test_stays = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_notes = True\n",
    "include_cxr = True\n",
    "include_ecg = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Time Series Embeddings: 100%|██████████| 51213/51213 [01:43<00:00, 492.81it/s]\n",
      "Calculating Text Embeddings: 100%|██████████| 51213/51213 [5:08:06<00:00,  2.77it/s]  \n",
      "Calculating CXR Embeddings: 100%|██████████| 51213/51213 [6:28:57<00:00,  2.19it/s]  \n"
     ]
    }
   ],
   "source": [
    "X_train = calc_ts_embeddings(train_stays)\n",
    "\n",
    "if include_notes:\n",
    "    txt_df = calc_avg_text_embedding(train_stays)\n",
    "    X_train = pd.concat([X_train, txt_df], axis=1)\n",
    "\n",
    "if include_cxr:\n",
    "    cxr_df = calc_avg_cxr_embedding(train_stays) \n",
    "    X_train = pd.concat([X_train, cxr_df], axis=1)\n",
    "\n",
    "if include_ecg:\n",
    "    ecg_df = calc_avg_ecg_embedding(train_stays)\n",
    "    X_train = pd.concat([X_train, ecg_df], axis=1)\n",
    "\n",
    "y_train = extract_labels(train_stays)\n",
    "\n",
    "col_names = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Time Series Embeddings: 100%|██████████| 5259/5259 [00:10<00:00, 513.74it/s]\n",
      "Calculating Text Embeddings:  50%|████▉     | 2608/5259 [00:26<01:08, 38.50it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Text Embeddings: 100%|██████████| 5259/5259 [02:12<00:00, 39.55it/s]\n",
      "Calculating CXR Embeddings: 100%|██████████| 5259/5259 [03:06<00:00, 28.22it/s] \n"
     ]
    }
   ],
   "source": [
    "X_test = calc_ts_embeddings(test_stays)\n",
    "\n",
    "if include_notes:\n",
    "    txt_df = calc_avg_text_embedding(test_stays)\n",
    "    X_test = pd.concat([X_test, txt_df], axis=1)\n",
    "\n",
    "if include_cxr:\n",
    "    cxr_df = calc_avg_cxr_embedding(test_stays)\n",
    "    X_test = pd.concat([X_test, cxr_df], axis=1)\n",
    "\n",
    "if include_ecg:\n",
    "    ecg_df = calc_avg_ecg_embedding(test_stays)\n",
    "    X_test = pd.concat([X_test, ecg_df], axis=1)\n",
    "\n",
    "y_test = extract_labels(test_stays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Time Series Embeddings:  60%|██████    | 3166/5262 [00:06<00:04, 504.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Time Series Embeddings: 100%|██████████| 5262/5262 [00:10<00:00, 506.38it/s]\n",
      "Calculating Text Embeddings: 100%|██████████| 5262/5262 [02:00<00:00, 43.70it/s] \n",
      "Calculating CXR Embeddings: 100%|██████████| 5262/5262 [03:12<00:00, 27.40it/s] \n"
     ]
    }
   ],
   "source": [
    "X_val = calc_ts_embeddings(val_stays)\n",
    "\n",
    "if include_notes:\n",
    "    txt_df = calc_avg_text_embedding(val_stays)\n",
    "    X_val = pd.concat([X_val, txt_df], axis=1)\n",
    "\n",
    "if include_cxr:\n",
    "    cxr_df = calc_avg_cxr_embedding(val_stays)\n",
    "    X_val = pd.concat([X_val, cxr_df], axis=1)\n",
    "\n",
    "if include_ecg:\n",
    "    ecg_df = calc_avg_ecg_embedding(val_stays)\n",
    "    X_val = pd.concat([X_val, ecg_df], axis=1)\n",
    "\n",
    "y_val = extract_labels(val_stays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y must have at least two dimensions for multi-output regression but has only one.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-2f2330ae307f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"pheno\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbase_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0my_pred_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_prob_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_prob_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_xgb_multilabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0my_pred_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_prob_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_prob_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_xgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/wang/junh/githubs/Multimodal-Transformer/src/preprocessing/mimiciv_preprocessing/prediction_util.py\u001b[0m in \u001b[0;36mrun_xgb_multilabel\u001b[0;34m(x_train, y_train, x_test, gpu, seed, n_jobs)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgs_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0my_pred_prob_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/wang/junh/envs/fuse_env/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    924\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/wang/junh/envs/fuse_env/lib/python3.8/site-packages/sklearn/multioutput.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfitted\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \"\"\"\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mestimator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/wang/junh/envs/fuse_env/lib/python3.8/site-packages/sklearn/multioutput.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    191\u001b[0m                 \u001b[0;34m\"y must have at least two dimensions for \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                 \u001b[0;34m\"multi-output regression but has only one.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: y must have at least two dimensions for multi-output regression but has only one."
     ]
    }
   ],
   "source": [
    "from prediction_util import run_xgb, run_xgb_multilabel\n",
    "\n",
    "seed = 1\n",
    "if \"pheno\" in base_name:\n",
    "    y_pred_test, y_pred_prob_test, y_pred_train, y_pred_prob_train, gs = run_xgb_multilabel(X_train, y_train, X_test, gpu=0, seed=seed, n_jobs=16)\n",
    "else:\n",
    "    y_pred_test, y_pred_prob_test, y_pred_train, y_pred_prob_train, gs = run_xgb(X_train, y_train, X_test, gpu=0, seed=seed, n_jobs=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pheno (no ECG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51213, 2122) (51213, 25) (5259, 2122) (5259,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5259,)\n",
      "(5259, 2)\n",
      "(24557,)\n",
      "(24557, 2)\n",
      "{'learning_rate': 0.05, 'max_depth': 6, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_test.shape)\n",
    "print(y_pred_prob_test.shape)\n",
    "print(y_pred_train.shape)\n",
    "print(y_pred_prob_train.shape)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOS (no ECG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5259,)\n",
      "(5259,)\n",
      "(24557,)\n",
      "(24557,)\n",
      "{'learning_rate': 0.05, 'max_depth': 6, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_test.shape)\n",
    "print(y_pred_prob_test.shape)\n",
    "print(y_pred_train.shape)\n",
    "print(y_pred_prob_train.shape)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of outcome: 0.4738543449324967\n",
      "F1 Score: 0.7221087803972527\n",
      "Accuracy: 0.7153451226468911\n",
      "Balanced Accuracy: 0.7185827318180737\n",
      "AUC: 0.7899929575871557\n",
      "AUPRC: 0.7317035269399694\n",
      "Confusion Matrix: [[1817  950]\n",
      " [ 547 1945]]\n"
     ]
    }
   ],
   "source": [
    "est = xgb.XGBClassifier(verbosity=2, seed=seed,eval_metric='logloss', n_jobs=32,learning_rate= 0.05, max_depth= 6, n_estimators= 200, device=\"cuda\")\n",
    "est.fit(X_train, y_train)\n",
    "\n",
    "y_pred_test = est.predict(X_test)\n",
    "y_pred_prob_test = est.predict_proba(X_test)\n",
    "\n",
    "# Evaluate\n",
    "_ = evaluate_model(y_test, y_pred_test, y_pred_prob_test[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for Training Set is: 0.82063233123592\n",
      "Accuracy for Training Set is: 0.8119477134829173\n",
      "Balanced Accuracy for Training Set is: 0.8149546634839877\n",
      "AUC for Training Set is: 0.8971280934763423\n",
      "AUPRC for Training Set is: 0.8722761350014441\n",
      "Confusion Matrix for Training Set is: \n",
      "[[ 9375  3369]\n",
      " [ 1249 10564]]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the training set\n",
    "y_pred_prob_train = est.predict_proba(X_train)\n",
    "y_pred_train = est.predict(X_train)\n",
    "\n",
    "# F1 Score for the training set\n",
    "f1_train = f1_score(y_train, y_pred_train)\n",
    "print(f\"F1 Score for Training Set is: {f1_train}\")\n",
    "\n",
    "# Accuracy for the training set\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "print(f\"Accuracy for Training Set is: {accuracy_train}\")\n",
    "\n",
    "# Balanced Accuracy for the training set\n",
    "balanced_accuracy_train = balanced_accuracy_score(y_train, y_pred_train)\n",
    "print(f\"Balanced Accuracy for Training Set is: {balanced_accuracy_train}\")\n",
    "\n",
    "# AUC for the training set\n",
    "# Ensure that y_pred_prob_train[:, 1] exists if it's a binary classification\n",
    "if len(np.unique(y_train)) == 2:\n",
    "    auc_train = roc_auc_score(y_train, y_pred_prob_train[:, 1])\n",
    "    print(f\"AUC for Training Set is: {auc_train}\")\n",
    "else:\n",
    "    print(\"AUC is typically used for binary classification. Adjust the code for multi-class if needed.\")\n",
    "\n",
    "# AUPRC for the training set\n",
    "if len(np.unique(y_train)) == 2:\n",
    "    auprc_train = average_precision_score(y_train, y_pred_prob_train[:, 1])\n",
    "    print(f\"AUPRC for Training Set is: {auprc_train}\")\n",
    "else:\n",
    "    print(\"AUPRC is typically used for binary classification. Adjust the code for multi-class if needed.\")\n",
    "\n",
    "# Confusion Matrix for the training set\n",
    "cm_train = confusion_matrix(y_train, y_pred_train)\n",
    "print(f\"Confusion Matrix for Training Set is: \\n{cm_train}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for Testing Set is: 0.7221087803972527\n",
      "Accuracy for Testing Set is: 0.7153451226468911\n",
      "Balanced Accuracy for Testing Set is: 0.7185827318180737\n",
      "AUC for Testing Set is: 0.7899929575871557\n",
      "AUPRC for Testing Set is: 0.7317035269399694\n",
      "Confusion Matrix for Testing Set is: \n",
      "[[1817  950]\n",
      " [ 547 1945]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, balanced_accuracy_score, roc_auc_score, average_precision_score, confusion_matrix\n",
    "\n",
    "# Assumed correction: Ensure y_pred_prob_test is fetched correctly and has two columns\n",
    "# y_pred_prob_test = model.predict_proba(X_test)  # Correctly fetching test probabilities\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, y_pred_test)\n",
    "print(f\"F1 Score for Testing Set is: {f1}\")\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print(f\"Accuracy for Testing Set is: {accuracy}\")\n",
    "\n",
    "# Balanced Accuracy\n",
    "balanced_accuracy = balanced_accuracy_score(y_test, y_pred_test)\n",
    "print(f\"Balanced Accuracy for Testing Set is: {balanced_accuracy}\")\n",
    "\n",
    "# AUC\n",
    "if y_pred_prob_test.ndim == 2 and y_pred_prob_test.shape[1] == 2:  # Ensuring binary classification with two probability outputs\n",
    "    auc = roc_auc_score(y_test, y_pred_prob_test[:, 1])\n",
    "    print(f\"AUC for Testing Set is: {auc}\")\n",
    "else:\n",
    "    print(\"Error: Expected binary class probabilities for AUC calculation.\")\n",
    "\n",
    "# AUPRC\n",
    "if y_pred_prob_test.ndim == 2 and y_pred_prob_test.shape[1] == 2:\n",
    "    auprc = average_precision_score(y_test, y_pred_prob_test[:, 1])\n",
    "    print(f\"AUPRC for Testing Set is: {auprc}\")\n",
    "else:\n",
    "    print(\"Error: Expected binary class probabilities for AUPRC calculation.\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "print(f\"Confusion Matrix for Testing Set is: \\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IHM (no ECG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5259,)\n",
      "(5259,)\n",
      "(24557,)\n",
      "(24557,)\n",
      "{'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_test.shape)\n",
    "print(y_pred_prob_test.shape)\n",
    "print(y_pred_train.shape)\n",
    "print(y_pred_prob_train.shape)\n",
    "print(gs.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample probabilities for training: [0.53186744 0.5715928  0.50406665 0.46213225 0.28154257]\n",
      "Sample probabilities for testing: [0.12913318 0.3875949  0.16137534 0.12450095 0.20820318]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample probabilities for training:\", y_pred_prob_train[:5])\n",
    "print(\"Sample probabilities for testing:\", y_pred_prob_test[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = MultiOutputClassifier(xgb.XGBClassifier(verbosity=2, seed=42,\n",
    "                                                  tree_method='gpu_hist', gpu_id=1,\n",
    "                                                  eval_metric='logloss', n_jobs=32,learning_rate= 0.05, max_depth= 5, n_estimators= 200))\n",
    "est.fit(X_train, y_train)\n",
    "y_pred_prob_test = est.predict_proba(X_test)\n",
    "y_pred_test = est.predict(X_test)\n",
    "# Evaluate\n",
    "_ = evaluate_model(y_test, y_pred_test, y_pred_prob_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of outcome: 0.1418520631298726\n",
      "F1 Score: 0.2694300518134715\n",
      "Accuracy: 0.8659440958357102\n",
      "Balanced Accuracy: 0.5772709640128102\n",
      "AUC: 0.8038226178885067\n",
      "AUPRC: 0.4391488439113681\n",
      "Confusion Matrix: [[4424   89]\n",
      " [ 616  130]]\n"
     ]
    }
   ],
   "source": [
    "est = xgb.XGBClassifier(verbosity=2, seed=seed,eval_metric='logloss', n_jobs=32,learning_rate= 0.05, max_depth= 5, n_estimators= 200, device=\"cuda\")\n",
    "est.fit(X_train, y_train)\n",
    "\n",
    "y_pred_test = est.predict(X_test)\n",
    "y_pred_prob_test = est.predict_proba(X_test)\n",
    "\n",
    "# Evaluate\n",
    "_ = evaluate_model(y_test, y_pred_test, y_pred_prob_test[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for Training Set is: 0.515621767018415\n",
      "Accuracy for Training Set is: 0.9046707659730423\n",
      "Balanced Accuracy for Training Set is: 0.6770478968464135\n",
      "AUC for Training Set is: 0.9052444653528526\n",
      "AUPRC for Training Set is: 0.7249747341606338\n",
      "Confusion Matrix for Training Set is: \n",
      "[[20970   127]\n",
      " [ 2214  1246]]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the training set\n",
    "y_pred_prob_train = est.predict_proba(X_train)\n",
    "y_pred_train = est.predict(X_train)\n",
    "\n",
    "# F1 Score for the training set\n",
    "f1_train = f1_score(y_train, y_pred_train)\n",
    "print(f\"F1 Score for Training Set is: {f1_train}\")\n",
    "\n",
    "# Accuracy for the training set\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "print(f\"Accuracy for Training Set is: {accuracy_train}\")\n",
    "\n",
    "# Balanced Accuracy for the training set\n",
    "balanced_accuracy_train = balanced_accuracy_score(y_train, y_pred_train)\n",
    "print(f\"Balanced Accuracy for Training Set is: {balanced_accuracy_train}\")\n",
    "\n",
    "# AUC for the training set\n",
    "# Ensure that y_pred_prob_train[:, 1] exists if it's a binary classification\n",
    "if len(np.unique(y_train)) == 2:\n",
    "    auc_train = roc_auc_score(y_train, y_pred_prob_train[:, 1])\n",
    "    print(f\"AUC for Training Set is: {auc_train}\")\n",
    "else:\n",
    "    print(\"AUC is typically used for binary classification. Adjust the code for multi-class if needed.\")\n",
    "\n",
    "# AUPRC for the training set\n",
    "if len(np.unique(y_train)) == 2:\n",
    "    auprc_train = average_precision_score(y_train, y_pred_prob_train[:, 1])\n",
    "    print(f\"AUPRC for Training Set is: {auprc_train}\")\n",
    "else:\n",
    "    print(\"AUPRC is typically used for binary classification. Adjust the code for multi-class if needed.\")\n",
    "\n",
    "# Confusion Matrix for the training set\n",
    "cm_train = confusion_matrix(y_train, y_pred_train)\n",
    "print(f\"Confusion Matrix for Training Set is: \\n{cm_train}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for Testing Set is: 0.2694300518134715\n",
      "Accuracy for Testing Set is: 0.8659440958357102\n",
      "Balanced Accuracy for Testing Set is: 0.5772709640128102\n",
      "AUC for Testing Set is: 0.8038226178885067\n",
      "AUPRC for Testing Set is: 0.4391488439113681\n",
      "Confusion Matrix for Testing Set is: \n",
      "[[4424   89]\n",
      " [ 616  130]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, balanced_accuracy_score, roc_auc_score, average_precision_score, confusion_matrix\n",
    "\n",
    "# Assumed correction: Ensure y_pred_prob_test is fetched correctly and has two columns\n",
    "# y_pred_prob_test = model.predict_proba(X_test)  # Correctly fetching test probabilities\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, y_pred_test)\n",
    "print(f\"F1 Score for Testing Set is: {f1}\")\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print(f\"Accuracy for Testing Set is: {accuracy}\")\n",
    "\n",
    "# Balanced Accuracy\n",
    "balanced_accuracy = balanced_accuracy_score(y_test, y_pred_test)\n",
    "print(f\"Balanced Accuracy for Testing Set is: {balanced_accuracy}\")\n",
    "\n",
    "# AUC\n",
    "if y_pred_prob_test.ndim == 2 and y_pred_prob_test.shape[1] == 2:  # Ensuring binary classification with two probability outputs\n",
    "    auc = roc_auc_score(y_test, y_pred_prob_test[:, 1])\n",
    "    print(f\"AUC for Testing Set is: {auc}\")\n",
    "else:\n",
    "    print(\"Error: Expected binary class probabilities for AUC calculation.\")\n",
    "\n",
    "# AUPRC\n",
    "if y_pred_prob_test.ndim == 2 and y_pred_prob_test.shape[1] == 2:\n",
    "    auprc = average_precision_score(y_test, y_pred_prob_test[:, 1])\n",
    "    print(f\"AUPRC for Testing Set is: {auprc}\")\n",
    "else:\n",
    "    print(\"Error: Expected binary class probabilities for AUPRC calculation.\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "print(f\"Confusion Matrix for Testing Set is: \\n{cm}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. Anion gap_max (0.083074)\n",
      "2. Bicarbonate_max (0.017980)\n",
      "3. Bicarbonate_maxdiff (0.009172)\n",
      "4. te_130 (0.008616)\n",
      "5. Anion gap_min (0.008259)\n",
      "6. Bicarbonate_min (0.007819)\n",
      "7. GCS - Eye Opening_min (0.007582)\n",
      "8. te_201 (0.006392)\n",
      "9. Alkaline Phosphate_max (0.006281)\n",
      "10. Anion gap_trend (0.006204)\n",
      "11. te_280 (0.006129)\n",
      "12. Diastolic BP_mean (0.005578)\n",
      "13. te_52 (0.005152)\n",
      "14. te_665 (0.005065)\n",
      "15. te_76 (0.005051)\n",
      "16. GCS - Eye Opening_mean (0.004789)\n",
      "17. Anion gap_sumabsdiff (0.004686)\n",
      "18. te_734 (0.004618)\n",
      "19. Alkaline Phosphate_mean (0.004582)\n",
      "20. Anion gap_mean (0.004333)\n",
      "21. Creatinine_variance (0.004297)\n",
      "22. Bicarbonate_trend (0.004241)\n",
      "23. te_147 (0.004133)\n",
      "24. te_319 (0.004056)\n",
      "25. Alkaline Phosphate_trend (0.004046)\n",
      "26. te_73 (0.003970)\n",
      "27. Bicarbonate_mean (0.003799)\n",
      "28. Creatinine_min (0.003569)\n",
      "29. te_235 (0.003500)\n",
      "30. te_25 (0.003483)\n",
      "31. te_357 (0.003422)\n",
      "32. Chloride_mean (0.003335)\n",
      "33. te_760 (0.003254)\n",
      "34. Alkaline Phosphate_min (0.003224)\n",
      "35. te_109 (0.003151)\n",
      "36. Creatinine_maxdiff (0.003140)\n",
      "37. te_564 (0.003131)\n",
      "38. te_107 (0.003041)\n",
      "39. te_231 (0.003041)\n",
      "40. te_515 (0.003026)\n",
      "41. te_39 (0.002997)\n",
      "42. Creatinine_diff (0.002990)\n",
      "43. te_335 (0.002980)\n",
      "44. te_105 (0.002970)\n",
      "45. Alkaline Phosphate_sumabsdiff (0.002960)\n",
      "46. Anion gap_variance (0.002935)\n",
      "47. te_250 (0.002926)\n",
      "48. te_292 (0.002918)\n",
      "49. te_393 (0.002881)\n",
      "50. te_482 (0.002879)\n"
     ]
    }
   ],
   "source": [
    "est.feature_importances_\n",
    "\n",
    "# Get the top 10 most important features\n",
    "indices = np.argsort(est.feature_importances_)[::-1]\n",
    "top_indices = indices[:100]\n",
    "print('Feature ranking:')\n",
    "for i in range(50):\n",
    "    print('%d. %s (%f)' % (i + 1, col_names[top_indices[i]], est.feature_importances_[top_indices[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: ihm-48-cxr-notes-missingInd\n",
      "Seed: 1\n",
      "Modals: ts+text+cxr\n",
      "\n",
      "\n",
      "TEST\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (5259, 2) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-deaade332736>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\nTEST\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_prob_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data/wang/junh/githubs/Multimodal-Transformer/src/preprocessing/mimiciv_preprocessing/npj_utils.py\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(y_true, y_pred, y_pred_prob)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mbalanced_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbalanced_accuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0mauprc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage_precision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mconf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/wang/junh/envs/fuse_env/lib/python3.8/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_binarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m         return _average_binary_score(\n\u001b[0m\u001b[1;32m    568\u001b[0m             \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_fpr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_fpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/wang/junh/envs/fuse_env/lib/python3.8/site-packages/sklearn/metrics/_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/wang/junh/envs/fuse_env/lib/python3.8/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    340\u001b[0m         )\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m     \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmax_fpr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmax_fpr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/wang/junh/envs/fuse_env/lib/python3.8/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m     \"\"\"\n\u001b[0;32m--> 962\u001b[0;31m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0m\u001b[1;32m    963\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m     )\n",
      "\u001b[0;32m/data/wang/junh/envs/fuse_env/lib/python3.8/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    733\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/wang/junh/envs/fuse_env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m   1039\u001b[0m         \u001b[0;34m\"y should be a 1d array, got an array of shape {} instead.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (5259, 2) instead."
     ]
    }
   ],
   "source": [
    "# print(\"TRAIN\")\n",
    "# _ = evaluate_model(y_train, y_pred_train, y_pred_prob_train)\n",
    "\n",
    "print(f\"Task: {base_name}\")\n",
    "print(f\"Seed: {seed}\")\n",
    "\n",
    "modals = \"ts\"\n",
    "\n",
    "if include_notes:\n",
    "    modals += \"+text\"\n",
    "\n",
    "if include_cxr:\n",
    "    modals += \"+cxr\"\n",
    "\n",
    "if include_ecg:\n",
    "    modals += \"+ecg\"\n",
    "\n",
    "print(f\"Modals: {modals}\")\n",
    "\n",
    "print(\"\\n\\nTEST\")\n",
    "_ = evaluate_model(y_test, y_pred_test, y_pred_prob_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
