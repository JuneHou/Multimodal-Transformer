{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_iv_path = \"/data/wang/junh/datasets/physionet.org/files/mimiciv/2.2\"\n",
    "mm_dir = \"/data/wang/junh/datasets/multimodal\"\n",
    "\n",
    "output_dir = os.path.join(mm_dir, \"preprocessing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "restrict_48_hours = True\n",
    "include_notes = True\n",
    "include_cxr = True\n",
    "include_ecg = True\n",
    "standard_scale = True\n",
    "include_missing = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['subject_id', 'hadm_id', 'stay_id', 'timedelta', 'Anion Gap',\n",
      "       'Bicarbonate', 'Calcium, Total', 'Chloride', 'Creatinine',\n",
      "       'Diastolic BP', 'GCS - Eye Opening', 'GCS - Motor Response',\n",
      "       'GCS - Verbal Response', 'Glucose', 'Heart Rate', 'Hematocrit',\n",
      "       'Hemoglobin', 'MCH', 'MCHC', 'MCV', 'Magnesium', 'Mean BP',\n",
      "       'Neutrophils', 'O2 Saturation', 'Phosphate', 'Platelet Count', 'RDW',\n",
      "       'Red Blood Cells', 'Respiratory Rate', 'Sodium', 'Systolic BP',\n",
      "       'Urea Nitrogen', 'Vancomycin', 'White Blood Cells'],\n",
      "      dtype='object')\n",
      "Index(['subject_id', 'hadm_id', 'stay_id', 'timedelta', 'Anion Gap',\n",
      "       'Bicarbonate', 'Calcium, Total', 'Chloride', 'Creatinine',\n",
      "       'Diastolic BP', 'GCS - Eye Opening', 'GCS - Motor Response',\n",
      "       'GCS - Verbal Response', 'Glucose', 'Heart Rate', 'Hematocrit',\n",
      "       'Hemoglobin', 'MCH', 'MCHC', 'MCV', 'Magnesium', 'Mean BP',\n",
      "       'Neutrophils', 'O2 Saturation', 'Phosphate', 'Platelet Count', 'RDW',\n",
      "       'Red Blood Cells', 'Respiratory Rate', 'Sodium', 'Systolic BP',\n",
      "       'Urea Nitrogen', 'Vancomycin', 'White Blood Cells'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "ireg_vitals_ts_df = pd.read_pickle(os.path.join(output_dir, \"ts_labs_vitals_new.pkl\"))\n",
    "ireg_vitals_ts_df = ireg_vitals_ts_df.drop(columns=[\"hosp_time_delta\"])\n",
    "ireg_vitals_ts_df.rename(columns={'icu_time_delta': 'timedelta'}, inplace=True)\n",
    "imputed_vitals = pd.read_pickle(os.path.join(output_dir, \"imputed_ts_labs_vitals_new.pkl\"))\n",
    "\n",
    "# ireg_vitals_ts_df = pd.read_pickle(os.path.join(output_dir, \"ts_labs_vitals_icu.pkl\"))\n",
    "# imputed_vitals = pd.read_pickle(os.path.join(output_dir, \"imputed_ts_labs_vitals_icu.pkl\"))\n",
    "print(ireg_vitals_ts_df.columns)\n",
    "print(imputed_vitals.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "print(len(ireg_vitals_ts_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ireg_vitals_ts_df = ireg_vitals_ts_df[ireg_vitals_ts_df['timedelta'] >= 0]\n",
    "imputed_vitals = imputed_vitals[imputed_vitals['timedelta'] >= 0]\n",
    "\n",
    "if restrict_48_hours:\n",
    "    ireg_vitals_ts_df = ireg_vitals_ts_df[ireg_vitals_ts_df['timedelta'] <= 48]\n",
    "    imputed_vitals = imputed_vitals[imputed_vitals['timedelta'] <= 48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['note_id_x', 'subject_id', 'hadm_id', 'note_type', 'note_seq',\n",
      "       'charttime', 'storetime', 'text', 'stay_id', 'icu_time_delta',\n",
      "       'hosp_time_delta', 'note_id_y', 'dis_text', 'biobert_embeddings',\n",
      "       'longformer_embeddings'],\n",
      "      dtype='object')\n",
      "Index(['dicom_id', 'subject_id', 'study_id',\n",
      "       'PerformedProcedureStepDescription', 'ViewPosition',\n",
      "       'ProcedureCodeSequence_CodeMeaning', 'ViewCodeSequence_CodeMeaning',\n",
      "       'PatientOrientationCodeSequence_CodeMeaning', 'densefeatures',\n",
      "       'predictions', 'cxrtime', 'hadm_id', 'stay_id', 'icu_time_delta',\n",
      "       'hosp_time_delta'],\n",
      "      dtype='object')\n",
      "Index(['subject_id', 'hadm_id', 'stay_id', 'icu_time_delta', 'ecg_time',\n",
      "       'path', 'embeddings'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "if include_notes:\n",
    "    notes_df = pd.read_pickle(os.path.join(output_dir, \"DuoAllchunk_icu_notes_text_embeddings.pkl\"))\n",
    "    print(notes_df.columns)\n",
    "    # notes_df = pd.read_pickle(os.path.join(output_dir, \"notes_text.pkl\"))\n",
    "    notes_df = notes_df[notes_df['stay_id'].notnull()]\n",
    "\n",
    "    notes_df = notes_df[notes_df['icu_time_delta'] >= 0]\n",
    "    if restrict_48_hours:\n",
    "        notes_df = notes_df[notes_df['icu_time_delta'] <= 48]\n",
    "\n",
    "if include_cxr:\n",
    "    cxr_df = pd.read_pickle(os.path.join(output_dir, \"cxr_embeddings_stay.pkl\"))\n",
    "    print(cxr_df.columns)\n",
    "    cxr_df = cxr_df[cxr_df['icu_time_delta'] >= 0]\n",
    "    if restrict_48_hours:\n",
    "        cxr_df = cxr_df[cxr_df['icu_time_delta'] <= 48]\n",
    "\n",
    "if include_ecg:\n",
    "    ecg_df = pd.read_pickle(os.path.join(output_dir, \"ecg_embeddings_icu.pkl\"))\n",
    "    print(ecg_df.columns)\n",
    "    ecg_df = ecg_df[ecg_df['icu_time_delta'] >= 0]\n",
    "    if restrict_48_hours:\n",
    "        ecg_df = ecg_df[ecg_df['icu_time_delta'] <= 48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo_notes = pd.read_csv(\"/data/wang/junh/datasets/multimodal/haim_replication/echo_embed.csv\")\n",
    "ecg_notes = pd.read_csv(\"/data/wang/junh/datasets/multimodal/haim_replication/ecg_embed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = pd.read_csv(\"/data/wang/junh/datasets/physionet.org/files/haim-multimodal/1.0.1/haim_mimiciv_key_ids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo_notes.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "echo_notes = pd.concat([keys, echo_notes], axis=1)\n",
    "ecg_notes.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "ecg_notes = pd.concat([keys, ecg_notes], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/wang/junh/envs/fuse_env/lib/python3.8/site-packages/pandas/core/reshape/merge.py:1214: RuntimeWarning: invalid value encountered in cast\n",
      "  if not (rk == rk.astype(lk.dtype))[~np.isnan(rk)].all():\n",
      "/data/wang/junh/envs/fuse_env/lib/python3.8/site-packages/pandas/core/reshape/merge.py:1214: RuntimeWarning: invalid value encountered in cast\n",
      "  if not (rk == rk.astype(lk.dtype))[~np.isnan(rk)].all():\n"
     ]
    }
   ],
   "source": [
    "notes_df = notes_df.merge(echo_notes, on=['subject_id', 'stay_id', 'hadm_id'], how=\"left\")\n",
    "notes_df = notes_df.merge(ecg_notes, on=['subject_id', 'stay_id', 'hadm_id'], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stays in ecg:  32937\n",
      "Number of stays in cxr:  13761\n",
      "Number of stays in notes:  55050\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of stays in ecg: \", ecg_df['stay_id'].nunique())\n",
    "print(\"Number of stays in cxr: \", cxr_df['stay_id'].nunique())\n",
    "print(\"Number of stays in notes: \", notes_df['stay_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "icustays_df = pd.read_csv(os.path.join(mimic_iv_path, \"icu\", \"icustays.csv.gz\"), low_memory=False)\n",
    "icustays_df['intime'] = pd.to_datetime(icustays_df['intime'])\n",
    "icustays_df['outtime'] = pd.to_datetime(icustays_df['outtime'])\n",
    "\n",
    "if restrict_48_hours:\n",
    "    icustays_df = icustays_df[icustays_df['los'] >= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_stay_ids = icustays_df['stay_id'].unique()\n",
    "\n",
    "ireg_vitals_ts_df = ireg_vitals_ts_df[ireg_vitals_ts_df['stay_id'].isin(valid_stay_ids)]\n",
    "imputed_vitals = imputed_vitals[imputed_vitals['stay_id'].isin(valid_stay_ids)]\n",
    "\n",
    "if include_notes:\n",
    "    notes_df = notes_df[notes_df['stay_id'].isin(valid_stay_ids)]\n",
    "\n",
    "if include_cxr:\n",
    "    cxr_df = cxr_df[cxr_df['stay_id'].isin(valid_stay_ids)]\n",
    "\n",
    "if include_ecg:\n",
    "    ecg_df = ecg_df[ecg_df['stay_id'].isin(valid_stay_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stays in ecg:  18272\n",
      "Number of stays in cxr:  8781\n",
      "Number of stays in notes:  31721\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of stays in ecg: \", ecg_df['stay_id'].nunique())\n",
    "print(\"Number of stays in cxr: \", cxr_df['stay_id'].nunique())\n",
    "print(\"Number of stays in notes: \", notes_df['stay_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['note_id_x', 'subject_id', 'hadm_id', 'note_type', 'note_seq',\n",
      "       'charttime', 'storetime', 'text', 'stay_id', 'icu_time_delta',\n",
      "       'hosp_time_delta', 'note_id_y', 'dis_text', 'biobert_embeddings',\n",
      "       'longformer_embeddings', 'echo_embed', 'ecg_embed'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(notes_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3014705, 34)\n"
     ]
    }
   ],
   "source": [
    "print(ireg_vitals_ts_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions_df = pd.read_csv(os.path.join(mimic_iv_path, \"hosp\", \"admissions.csv.gz\"))\n",
    "admissions_df = admissions_df.rename(columns={\"hospital_expire_flag\": \"died\"})\n",
    "admissions_df = admissions_df[[\"subject_id\", \"hadm_id\", \"died\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stays with vitals: 35131\n",
      "Number of stays with either TS or notes: 35131\n",
      "Number of stays with either TS, notes, cxr: 35131\n",
      "Number of stays with either TS, notes, cxr, ecg: 35131\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if not include_missing:\n",
    "    unique_stays = ireg_vitals_ts_df['stay_id'].unique()\n",
    "    print(f\"Number of stays with vitals: {len(unique_stays)}\")\n",
    "\n",
    "    if include_notes:\n",
    "        unique_stays = np.intersect1d(unique_stays, notes_df['stay_id'].unique())\n",
    "        print(f\"Number of stays with notes: {len(unique_stays)}\")\n",
    "\n",
    "    if include_cxr:\n",
    "        unique_stays = np.intersect1d(unique_stays, cxr_df['stay_id'].unique())\n",
    "        print(f\"Number of stays with cxr: {len(unique_stays)}\")\n",
    "\n",
    "    if include_ecg:\n",
    "        unique_stays = np.intersect1d(unique_stays, ecg_df['stay_id'].unique())\n",
    "        print(f\"Number of stays with ecg: {len(unique_stays)}\")\n",
    "else:\n",
    "    unique_stays = ireg_vitals_ts_df['stay_id'].unique()\n",
    "    print(f\"Number of stays with vitals: {len(unique_stays)}\")\n",
    "\n",
    "    if include_notes:\n",
    "        # Get stays with either TS or notes\n",
    "        unique_stays = np.union1d(unique_stays, notes_df['stay_id'].unique())\n",
    "        print(f\"Number of stays with either TS or notes: {len(unique_stays)}\")\n",
    "    \n",
    "    if include_cxr:\n",
    "        unique_stays = np.union1d(unique_stays, cxr_df['stay_id'].unique())\n",
    "        print(f\"Number of stays with either TS, notes, cxr: {len(unique_stays)}\")\n",
    "    \n",
    "    if include_ecg:\n",
    "        unique_stays = np.union1d(unique_stays, ecg_df['stay_id'].unique())\n",
    "        print(f\"Number of stays with either TS, notes, cxr, ecg: {len(unique_stays)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train, val, test splits\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(unique_stays)\n",
    "train_stays = unique_stays[:int(0.7*len(unique_stays))]\n",
    "val_stays = unique_stays[int(0.7*len(unique_stays)):int(0.85*len(unique_stays))]\n",
    "test_stays = unique_stays[int(0.85*len(unique_stays)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ireg_ts_df = ireg_vitals_ts_df[ireg_vitals_ts_df['stay_id'].isin(train_stays)].copy()\n",
    "train_imputed_df = imputed_vitals[imputed_vitals['stay_id'].isin(train_stays)].copy()\n",
    "\n",
    "cols = train_ireg_ts_df.columns.tolist()\n",
    "cols = [col for col in cols if col not in ['subject_id', 'hadm_id', 'stay_id', 'timedelta']]\n",
    "\n",
    "if standard_scale:\n",
    "    for col in cols:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(train_ireg_ts_df[[col]])\n",
    "        ireg_vitals_ts_df[col] = scaler.transform(ireg_vitals_ts_df[[col]])\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(train_imputed_df[[col]])\n",
    "        imputed_vitals[col] = scaler.transform(imputed_vitals[[col]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['subject_id', 'hadm_id', 'stay_id', 'timedelta', 'Anion Gap',\n",
      "       'Bicarbonate', 'Calcium, Total', 'Chloride', 'Creatinine',\n",
      "       'Diastolic BP', 'GCS - Eye Opening', 'GCS - Motor Response',\n",
      "       'GCS - Verbal Response', 'Glucose', 'Heart Rate', 'Hematocrit',\n",
      "       'Hemoglobin', 'MCH', 'MCHC', 'MCV', 'Magnesium', 'Mean BP',\n",
      "       'Neutrophils', 'O2 Saturation', 'Phosphate', 'Platelet Count', 'RDW',\n",
      "       'Red Blood Cells', 'Respiratory Rate', 'Sodium', 'Systolic BP',\n",
      "       'Urea Nitrogen', 'Vancomycin', 'White Blood Cells'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_ireg_ts_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stay_list(stays):\n",
    "    stays_list = []\n",
    "\n",
    "    for curr_stay in tqdm(stays):\n",
    "        \n",
    "        curr_stay_ireg = ireg_vitals_ts_df[ireg_vitals_ts_df['stay_id'] == curr_stay].copy()\n",
    "        #print(f\"Initial irregular time series shape (before dropping columns): {curr_stay_ireg.shape}\")\n",
    "        curr_stay_imputed = imputed_vitals[imputed_vitals['stay_id'] == curr_stay].copy()\n",
    "\n",
    "        if len(curr_stay_ireg) == 0:\n",
    "            continue\n",
    "\n",
    "        curr_stay_dict = {}\n",
    "        curr_stay_dict['name'] = curr_stay_ireg['subject_id'].iloc[0]\n",
    "        curr_stay_dict['hadm_id'] = curr_stay_ireg['hadm_id'].iloc[0]\n",
    "        curr_stay_dict['stay_id'] = curr_stay\n",
    "        curr_stay_dict['ts_tt'] = curr_stay_ireg['timedelta'].values\n",
    "\n",
    "        curr_stay_ireg.drop(columns=['subject_id', 'hadm_id', 'stay_id', 'timedelta'], inplace=True)\n",
    "        ireg_ts_mask = curr_stay_ireg.notnull()\n",
    "        curr_stay_ireg.fillna(0, inplace=True)\n",
    "        curr_stay_dict['irg_ts'] = curr_stay_ireg.values\n",
    "        curr_stay_dict['irg_ts_mask'] = ireg_ts_mask.values.astype(int)\n",
    "\n",
    "        curr_stay_imputed.drop(columns=['subject_id', 'hadm_id', 'stay_id', 'timedelta'], inplace=True)\n",
    "        curr_stay_dict['reg_ts'] = curr_stay_imputed.values\n",
    "\n",
    "        if include_notes:\n",
    "            curr_stay_notes = notes_df[notes_df['stay_id'] == curr_stay].copy()\n",
    "\n",
    "            if len(curr_stay_notes) == 0:\n",
    "                curr_stay_dict['text_data'] = []\n",
    "                curr_stay_dict['text_time_to_end'] = []\n",
    "                curr_stay_dict['text_embeddings'] = []\n",
    "                curr_stay_dict['text_missing'] = 1\n",
    "            else:\n",
    "                curr_stay_dict['text_data'] = curr_stay_notes['text'].tolist() + curr_stay_notes['dis_text'].tolist()\n",
    "                curr_stay_dict['text_time_to_end'] = curr_stay_notes['icu_time_delta'].values\n",
    "                #curr_stay_dict['text_embeddings'] = [emb[0][0] for emb in curr_stay_notes['biobert_embeddings']]\n",
    "                curr_stay_dict['rad_embeddings'] = [\n",
    "                    np.mean([chunk[0] for chunk in emb], axis=0) for emb in curr_stay_notes['biobert_embeddings']\n",
    "                ]\n",
    "                print(\"shape of rad embeddings: \", curr_stay_notes['biobert_embeddings'].shape)\n",
    "                curr_stay_dict['note_embeddings'] = [\n",
    "                    emb[0] for emb in curr_stay_notes['longformer_embeddings']\n",
    "                ]\n",
    "                print(\"shape of note embeddings: \", curr_stay_dict['note_embeddings'][0].shape)\n",
    "                # Concatenate embeddings for each note\n",
    "                curr_stay_dict['text_embeddings'] = [np.concatenate((rad_emb, note_emb)) for rad_emb, note_emb in zip(curr_stay_dict['rad_embeddings'], curr_stay_dict['note_embeddings'])]\n",
    "                print(\"Length of embeddings: \", len(curr_stay_dict['text_embeddings'][0]))\n",
    "                curr_stay_dict['text_missing'] = 0\n",
    "            \n",
    "        if include_cxr:\n",
    "            curr_stay_cxr = cxr_df[cxr_df['stay_id'] == curr_stay].copy()\n",
    "            \n",
    "            if len(curr_stay_cxr) == 0:\n",
    "                curr_stay_dict['cxr_feats'] = []\n",
    "                curr_stay_dict['cxr_time'] = []\n",
    "                curr_stay_dict['cxr_missing'] = 1\n",
    "            else:\n",
    "                curr_stay_dict['cxr_feats'] = curr_stay_cxr['densefeatures'].tolist()\n",
    "                curr_stay_dict['cxr_time'] = curr_stay_cxr['icu_time_delta'].values\n",
    "                curr_stay_dict['cxr_missing'] = 0\n",
    "                #print(f\"Number of CXR features: {len(curr_stay_dict['cxr_feats'])}\")\n",
    "\n",
    "        if include_ecg:\n",
    "            curr_stay_ecg = ecg_df[ecg_df['stay_id'] == curr_stay].copy()\n",
    "            if len(curr_stay_ecg) == 0:\n",
    "                curr_stay_dict['ecg_feats'] = []\n",
    "                curr_stay_dict['ecg_time'] = []\n",
    "                curr_stay_dict['ecg_missing'] = 1\n",
    "            else:\n",
    "                curr_stay_dict['ecg_feats'] = curr_stay_ecg['embeddings'].tolist()\n",
    "                curr_stay_dict['ecg_time'] = curr_stay_ecg['icu_time_delta'].values\n",
    "                curr_stay_dict['ecg_missing'] = 0\n",
    "\n",
    "        curr_stay_dict['label'] = admissions_df[admissions_df['hadm_id'] == curr_stay_dict['hadm_id']]['died'].iloc[0]\n",
    "\n",
    "        stays_list.append(curr_stay_dict)\n",
    "\n",
    "    return stays_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24591 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/data/wang/junh/envs/fuse_env/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3621\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3622\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/wang/junh/envs/fuse_env/lib/python3.8/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/data/wang/junh/envs/fuse_env/lib/python3.8/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-449e6fb7497d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_stays_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_stay_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_stays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_stays_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_stay_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_stays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_stays_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_stay_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_stays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-bf05d7f811a2>\u001b[0m in \u001b[0;36mget_stay_list\u001b[0;34m(stays)\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0memb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcurr_stay_notes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'biobert_embeddings'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 ]\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"shape of rad embeddings: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_stay_notes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'biobert_embeddings'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                 curr_stay_dict['note_embeddings'] = [\n\u001b[1;32m     45\u001b[0m                     \u001b[0memb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0memb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcurr_stay_notes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'longformer_embeddings'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/wang/junh/envs/fuse_env/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 958\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/wang/junh/envs/fuse_env/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/wang/junh/envs/fuse_env/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3622\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3623\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3624\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3625\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "train_stays_list = get_stay_list(train_stays)\n",
    "val_stays_list = get_stay_list(val_stays)\n",
    "test_stays_list = get_stay_list(test_stays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  6.59it/s]\n"
     ]
    }
   ],
   "source": [
    "# Example to check the first patient stay\n",
    "first_stay = train_stays[18]\n",
    "first_stay_data = get_stay_list([first_stay])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving train stays to /data/wang/junh/datasets/multimodal/preprocessing/train_ihm-48-cxr-notes-ecg-missingInd-dis_stays.pkl\n",
      "Saving val stays to /data/wang/junh/datasets/multimodal/preprocessing/val_ihm-48-cxr-notes-ecg-missingInd-dis_stays.pkl\n",
      "Saving test stays to /data/wang/junh/datasets/multimodal/preprocessing/test_ihm-48-cxr-notes-ecg-missingInd-dis_stays.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save the data\n",
    "import pickle\n",
    "\n",
    "base_name = \"ihm\"\n",
    "if restrict_48_hours:\n",
    "    base_name += \"-48\"\n",
    "else:\n",
    "    base_name += \"-all\"\n",
    "\n",
    "if include_cxr:\n",
    "    if include_notes:\n",
    "        base_name += \"-cxr-notes\"\n",
    "    else:\n",
    "        base_name += \"-cxr\"\n",
    "\n",
    "if include_ecg:\n",
    "    base_name += \"-ecg\"\n",
    "\n",
    "if include_missing:\n",
    "    base_name += \"-missingInd-two\"\n",
    "\n",
    "f_path = os.path.join(output_dir, f\"train_{base_name}_stays.pkl\")\n",
    "with open(f_path, 'wb') as f:\n",
    "    print(f\"Saving train stays to {f_path}\")\n",
    "    pickle.dump(train_stays_list, f)\n",
    "\n",
    "f_path = os.path.join(output_dir, f\"val_{base_name}_stays.pkl\")\n",
    "with open(f_path, 'wb') as f:\n",
    "    print(f\"Saving val stays to {f_path}\")\n",
    "    pickle.dump(val_stays_list, f)\n",
    "\n",
    "f_path = os.path.join(output_dir, f\"test_{base_name}_stays.pkl\")\n",
    "with open(f_path, 'wb') as f:\n",
    "    print(f\"Saving test stays to {f_path}\")\n",
    "    pickle.dump(test_stays_list, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3624\n"
     ]
    }
   ],
   "source": [
    "# Save the data\n",
    "import pickle\n",
    "file_path = '/data/wang/junh/datasets/multimodal/preprocessing/train_ihm-48-cxr-notes-ecg_stays.pkl'\n",
    "with open(file_path, 'rb') as f:\n",
    "    train_stays_list = pickle.load(f)\n",
    "print(len(train_stays_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['name', 'hadm_id', 'stay_id', 'ts_tt', 'irg_ts', 'irg_ts_mask', 'reg_ts', 'text_data', 'text_time_to_end', 'text_embeddings', 'text_missing', 'cxr_feats', 'cxr_time', 'cxr_missing', 'ecg_feats', 'ecg_time', 'ecg_missing', 'label'])\n"
     ]
    }
   ],
   "source": [
    "print(train_stays_list[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "print(len(train_stays_list[1]['reg_ts']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fuse_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
